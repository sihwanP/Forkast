from django.conf import settings
import logging
import time
import random
import json
import re
from typing import Optional, Dict, Any

logger = logging.getLogger(__name__)

# Models to try in order
AVAILABLE_MODELS = [
    'gemini-2.0-flash',      # Latest fast model
    'gemini-1.5-flash',      # Standard fast model
    'gemini-1.5-pro',        # High intelligence fallback
]

def get_gemini_response(prompt: str) -> Optional[str]:
    """
    Simulates or calls Gemini API to get text response.
    Handles retry logic and model fallback.
    """
    # Lazy Import & Config (New SDK)
    try:
        from google import genai
        from google.genai import types
        client = genai.Client(api_key=settings.GEMINI_API_KEY)
    except Exception as e:
        debug_msg = f"Import Error in Analytics Service: {e}"
        # Ideally use proper logging instead of file write in production
        logger.error(debug_msg)
        # In this context, we return None to let caller handle it or raise
        # But keeping existing behavior of raising for import error vs returning None for api error
        # Actually existing code raises Exception on import error.
        raise Exception(debug_msg)

    first_error = None
    
    # Retry configuration
    max_retries = 3
    base_delay = 1  # seconds

    for i, model_name in enumerate(AVAILABLE_MODELS):
        for attempt in range(max_retries + 1):
            try:
                # Enforce 15s timeout via config if possible, or client defaults
                config = types.GenerateContentConfig()
                
                response = client.models.generate_content(
                    model=model_name,
                    contents=prompt,
                    config=config
                )
                return response.text
            except Exception as e:
                error_str = str(e)
                # Check for 429 (Resource Exhausted)
                if "429" in error_str or "Resource exhausted" in error_str:
                    if attempt < max_retries:
                        delay = (base_delay * (2 ** attempt)) + random.uniform(0, 1)
                        logger.warning(f"Rate limit hit for {model_name}. Retrying in {delay:.2f}s... (Attempt {attempt+1}/{max_retries})")
                        time.sleep(delay)
                        continue
                
                # Non-retriable error or max retries reached
                logger.warning(f"Failed with model {model_name}: {e}")
                if i == 0 and first_error is None:
                    first_error = e
                break # Move to next model
    
    error_msg = str(first_error) if first_error else "Unknown error"
    logger.error(f"All Gemini models failed. Primary error: {error_msg}")
    return None

def get_mock_dashboard_data(revenue_today: int) -> Dict[str, Any]:
    """
    Returns realistic dummy data when AI is offline.
    """
    return {
        "prediction": int(revenue_today * 1.2),
        "analysis": "â˜ï¸ AI ì—°ê²° ëŒ€ê¸° ì¤‘ (ì˜¤í”„ë¼ì¸ ëª¨ë“œ): í˜„ì¬ ë„¤íŠ¸ì›Œí¬ ìƒíƒœë¡œ ì¸í•´ AI ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ëŒ€ì‹  ê¸°ë³¸ ì˜ˆì¸¡ ëª¨ë¸ì´ ì‘ë™ ì¤‘ì…ë‹ˆë‹¤.",
        "strategies": [
            { "category": "ì¸ë ¥", "icon": "ğŸ‘¥", "title": "í˜„ì¥ ì¤‘ì‹¬ ìš´ì˜", "summary": "í”¼í¬íƒ€ì„ ëŒ€ë¹„", "detail": "í‰ì†Œ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì ì‹¬/ì €ë… í”¼í¬íƒ€ì„ì— ì§‘ì¤‘í•´ì£¼ì„¸ìš”.", "score": 80 },
            { "category": "ì¬ê³ ", "icon": "ğŸ“¦", "title": "í•„ìˆ˜ ì¬ê³  ì ê²€", "summary": "ì£¼ìš” í’ˆëª© í™•ì¸", "detail": "ìœ¡ì•ˆìœ¼ë¡œ ì£¼ìš” ìì¬ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.", "score": 85 },
            { "category": "ë§ˆì¼€íŒ…", "icon": "ğŸ“£", "title": "ë‹¨ê³¨ ê³ ê° ê´€ë¦¬", "summary": "ê¸°ì¡´ ì„œë¹„ìŠ¤ ìœ ì§€", "detail": "ë‹¨ê³¨ ê³ ê° ì´ë²¤íŠ¸ë¥¼ ì§„í–‰í•´ë³´ì„¸ìš”.", "score": 75 }
        ],
        "cheer_msg": "ë„¤íŠ¸ì›Œí¬ëŠ” ì ì‹œ ì‰¬ì–´ê°€ë„, ì‚¬ì¥ë‹˜ì˜ ì—´ì •ì€ ë©ˆì¶”ì§€ ì•ŠìŠµë‹ˆë‹¤! í˜ë‚´ì„¸ìš”! ğŸ”¥"
    }

def generate_dashboard_analysis(sales_data: Dict, weather_data: str, inventory_data: str, event_data: str) -> Dict[str, Any]:
    """
    Combined AI Analyzer: Predicts revenue, analyzes flow, suggests strategy, and cheers.
    Everything in ONE call.
    """
    history_str = "\n".join(sales_data.get('history', []))
    revenue_today = sales_data.get('revenue', 0)
    
    prompt = f"""
    ë‹¹ì‹ ì€ 'Forkast AI'ì˜ ìˆ˜ì„ ë¶„ì„ê°€ì…ë‹ˆë‹¤.
    ë‹¤ìŒ ë§¤ì¥ ë°ì´í„°ë¥¼ ì¢…í•© ë¶„ì„í•˜ì—¬, 4ê°€ì§€ í•µì‹¬ ì •ë³´ë¥¼ **JSON í¬ë§·**ìœ¼ë¡œ í•œ ë²ˆì— ì¶œë ¥í•˜ì„¸ìš”.
    
    [ì…ë ¥ ë°ì´í„°]
    1. 30ì¼ ë§¤ì¶œ ì¶”ì´:
    {history_str}
    
    2. ì˜¤ëŠ˜ í˜„í™©:
    - í˜„ì¬ ë§¤ì¶œ: {revenue_today}ì›
    - ë‚ ì”¨: {weather_data}
    - ì¬ê³ : {inventory_data}
    - ì´ë²¤íŠ¸: {event_data}
    
    [ìš”ì²­ ì‚¬í•­]
    ë‹¤ìŒ 4ê°€ì§€ í•„ë“œë¥¼ í¬í•¨í•œ JSON ê°ì²´ë¥¼ ë°˜í™˜í•˜ì„¸ìš”.
    1. "prediction" (Number): ìµœì¢… ì˜ˆìƒ ë§¤ì¶œ.
    2. "analysis" (String): ì‹¤ì‹œê°„ ë§¤ì¶œ íë¦„ ë¶„ì„ (í•œ ë¬¸ë‹¨).
    3. "strategies" (Array): ìµœì  ìš´ì˜ ì „ëµ 3ê°€ì§€.
    4. "cheer_msg" (String): ì‚¬ì¥ë‹˜ì„ ìœ„í•œ ì§§ê³  ê°ì„±ì ì¸ ì‘ì› ë©”ì‹œì§€.
    
    âš ï¸ ì˜¤ì§ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”. ë§ˆí¬ë‹¤ìš´ ì‚¬ìš© ê¸ˆì§€.
    """
    
    response_text = get_gemini_response(prompt)
    
    if response_text is None:
        return get_mock_dashboard_data(revenue_today)

    try:
        clean_text = re.sub(r'```json\s*|\s*```', '', response_text).strip()
        data = json.loads(clean_text)
        return data
    except Exception as e:
        logger.error(f"Failed to parse Unified AI JSON: {e}")
        return get_mock_dashboard_data(revenue_today)

def consult_ai(question: str) -> Optional[str]:
    prompt = f"""
    ë‹¹ì‹ ì€ ìì˜ì—…ìë¥¼ ìœ„í•œ ì „ë¬¸ AI ë¹„ì„œì…ë‹ˆë‹¤.
    ì§ˆë¬¸: "{question}"
    í•µì‹¬ë§Œ ìš”ì•½í•´ì„œ ë‹µë³€í•´ì¤˜ (ê³µì†í•œ í†¤ì•¤ë§¤ë„ˆ).
    """
    return get_gemini_response(prompt)
