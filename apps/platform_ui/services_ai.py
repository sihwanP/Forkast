from django.conf import settings
import logging
import time
import random
import json
import re

logger = logging.getLogger(__name__)

# Models to try in order
AVAILABLE_MODELS = [
    'gemini-2.0-flash',      # Latest fast model
    'gemini-1.5-flash',      # Standard fast model
    'gemini-1.5-pro',        # High intelligence fallback
]

def get_gemini_response(prompt):
    """
    Hybrid Client: Tries google.genai (New) -> Falls back to google.generativeai (Legacy).
    """
    response_text = None
    
    # ---------------------------------------------------------
    # STRATEGY 1: New SDK (google.genai)
    # ---------------------------------------------------------
    try:
        from google import genai
        from google.genai import types
        
        client = genai.Client(api_key=settings.GEMINI_API_KEY)
        
        for model_name in AVAILABLE_MODELS:
            try:
                config = types.GenerateContentConfig()
                response = client.models.generate_content(
                    model=model_name,
                    contents=prompt,
                    config=config
                )
                if response.text:
                    return response.text
            except Exception as e:
                # 429 logic or continue
                continue
                
    except ImportError:
        logger.warning("google.genai SDK not found or broken. Falling back to Legacy SDK.")
    except Exception as e:
         logger.warning(f"New SDK failed: {e}. Falling back to Legacy SDK.")
    # STRATEGY 2: Legacy SDK (google.generativeai)
    # ---------------------------------------------------------
    try:
        import google.generativeai as genai_legacy
        genai_legacy.configure(api_key=settings.GEMINI_API_KEY)
        
        for model_name in AVAILABLE_MODELS:
            try:
                model = genai_legacy.GenerativeModel(model_name)
                response = model.generate_content(prompt, request_options={'timeout': 15})
                if response.text:
                    return response.text
            except Exception:
                continue
                
    except ImportError:
         logger.error("CRITICAL: Both New and Legacy SDKs failed to import.")
    except Exception as e:
         logger.error(f"Legacy SDK failed: {e}")

    return None

def get_mock_dashboard_data(revenue_today):
    """
    Returns realistic dummy data when AI is offline.
    """
    return {
        "prediction": int(revenue_today * 1.2),
        "analysis": "â˜ï¸ AI ì—°ê²° ëŒ€ê¸° ì¤‘ (ì˜¤í”„ë¼ì¸ ëª¨ë“œ): í˜„ì¬ ë„¤íŠ¸ì›Œí¬ ìƒíƒœë¡œ ì¸í•´ AI ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ëŒ€ì‹  ê¸°ë³¸ ì˜ˆì¸¡ ëª¨ë¸ì´ ì‘ë™ ì¤‘ì…ë‹ˆë‹¤. ë‚ ì”¨ì™€ ë§¤ì¶œ ì¶”ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìƒìŠ¹ì„¸ê°€ ì˜ˆìƒë©ë‹ˆë‹¤.",
        "strategies": [
            { "category": "ì¸ë ¥", "icon": "ğŸ‘¥", "title": "í˜„ì¥ ì¤‘ì‹¬ ìš´ì˜", "summary": "í”¼í¬íƒ€ì„ ëŒ€ë¹„", "detail": "AI ì—°ê²°ì´ ì›í™œí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. í‰ì†Œ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì ì‹¬/ì €ë… í”¼í¬íƒ€ì„ì— ì§‘ì¤‘í•´ì£¼ì„¸ìš”.", "score": 80 },
            { "category": "ì¬ê³ ", "icon": "ğŸ“¦", "title": "í•„ìˆ˜ ì¬ê³  ì ê²€", "summary": "ì£¼ìš” í’ˆëª© í™•ì¸", "detail": "ë„¤íŠ¸ì›Œí¬ ì´ìŠˆë¡œ ì‹¤ì‹œê°„ ì¬ê³  ë¶„ì„ì´ ì§€ì—°ë˜ê³  ìˆìŠµë‹ˆë‹¤. ìœ¡ì•ˆìœ¼ë¡œ ì£¼ìš” ìì¬ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.", "score": 85 },
            { "category": "ë§ˆì¼€íŒ…", "icon": "ğŸ“£", "title": "ë‹¨ê³¨ ê³ ê° ê´€ë¦¬", "summary": "ê¸°ì¡´ ì„œë¹„ìŠ¤ ìœ ì§€", "detail": "ë¬¸ìë‚˜ SNSë¥¼ í†µí•´ ê¸ˆì¼ ì˜ì—… ì‹œê°„ì„ ì•ˆë‚´í•˜ê³  ë‹¨ê³¨ ê³ ê° ì´ë²¤íŠ¸ë¥¼ ì§„í–‰í•´ë³´ì„¸ìš”.", "score": 75 }
        ],
        "cheer_msg": "ë„¤íŠ¸ì›Œí¬ëŠ” ì ì‹œ ì‰¬ì–´ê°€ë„, ì‚¬ì¥ë‹˜ì˜ ì—´ì •ì€ ë©ˆì¶”ì§€ ì•ŠìŠµë‹ˆë‹¤! í˜ë‚´ì„¸ìš”! ğŸ”¥"
    }

def generate_dashboard_analysis(sales_data, weather_data, inventory_data, event_data):
    """
    Combined AI Analyzer: Predicts revenue, analyzes flow, suggests strategy, and cheers.
    Everything in ONE call to speed up loading time (< 10s).
    """
    history_str = "\n".join(sales_data.get('history', []))
    revenue_today = sales_data.get('revenue', 0)
    
    prompt = f"""
    ë‹¹ì‹ ì€ 'Forkast AI'ì˜ ìˆ˜ì„ ë¶„ì„ê°€ì…ë‹ˆë‹¤.
    ë‹¤ìŒ ë§¤ì¥ ë°ì´í„°ë¥¼ ì¢…í•© ë¶„ì„í•˜ì—¬, 4ê°€ì§€ í•µì‹¬ ì •ë³´ë¥¼ **JSON í¬ë§·**ìœ¼ë¡œ í•œ ë²ˆì— ì¶œë ¥í•˜ì„¸ìš”.
    
    [ì…ë ¥ ë°ì´í„°]
    1. 30ì¼ ë§¤ì¶œ ì¶”ì´:
    {history_str}
    
    2. ì˜¤ëŠ˜ í˜„í™©:
    - í˜„ì¬ ë§¤ì¶œ: {revenue_today}ì›
    - ë‚ ì”¨: {weather_data}
    - ì¬ê³ : {inventory_data}
    - ì´ë²¤íŠ¸: {event_data}
    
    [ë¶„ì„ í•µì‹¬ ìš”êµ¬ì‚¬í•­]
    - **ê°€ì¥ ì¤‘ìš”:** '30ì¼ ë§¤ì¶œ ì¶”ì´' ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì˜¤ëŠ˜ì˜ 'ë‚ ì”¨'ì™€ 'ì´ë²¤íŠ¸'ê°€ ë§¤ì¶œì— ë¯¸ì¹  ì˜í–¥ì„ ë¶„ì„í•˜ì„¸ìš”. ë‹¨ìˆœíˆ í˜„ì¬ ìˆ˜ì¹˜ë§Œ ë³´ì§€ ë§ê³ , ê³¼ê±° íŒ¨í„´(ìš”ì¼/ë‚ ì”¨ ë“±)ê³¼ ë¹„êµí•˜ì—¬ ì¸ì‚¬ì´íŠ¸ë¥¼ ë„ì¶œí•´ì•¼ í•©ë‹ˆë‹¤.
    
    [ìš”ì²­ ì‚¬í•­]
    ë‹¤ìŒ 4ê°€ì§€ í•„ë“œë¥¼ í¬í•¨í•œ JSON ê°ì²´ë¥¼ ë°˜í™˜í•˜ì„¸ìš”.
    
    1. "prediction" (Number): ê³¼ê±° ì¶”ì„¸ì™€ ì˜¤ëŠ˜ ë³€ìˆ˜(ë‚ ì”¨/ì´ë²¤íŠ¸)ë¥¼ ì¢…í•©í•œ ìµœì¢… ì˜ˆìƒ ë§¤ì¶œ.
    2. "analysis" (String): ì‹¤ì‹œê°„ ë§¤ì¶œ íë¦„ ë¶„ì„ (í•œ ë¬¸ë‹¨). "ğŸ“ˆ ìƒìŠ¹ì„¸/í•˜ë½ì„¸: ë‚ ì”¨ì™€ ì´ë²¤íŠ¸ ì˜í–¥ìœ¼ë¡œ ~~~." í˜•ì‹.
    3. "strategies" (Array): ìµœì  ìš´ì˜ ì „ëµ 3ê°€ì§€ (ì¸ë ¥/ì¬ê³ /ë§ˆì¼€íŒ…).
        - ê° ê°ì²´: {{ "category": "ì¸ë ¥", "icon": "ğŸ‘¥", "title": "...", "summary": "...", "detail": "...", "score": 85 }}
    4. "cheer_msg" (String): ì˜¤ëŠ˜ ì´ë§¤ì¶œ({revenue_today}ì›)ì„ ê¸°ì¤€ìœ¼ë¡œ, ë§¤ì¶œì´ ë†’ìœ¼ë©´ ì¶•í•˜í•˜ê³  ë‚®ìœ¼ë©´ ê²©ë ¤í•˜ëŠ” êµ¬ì²´ì ì´ê³  ë”°ëœ»í•œ íë§ ë©”ì‹œì§€ (50ì ì´ë‚´).
    
    [JSON ì¶œë ¥ ì˜ˆì‹œ - ì—„ê²© ì¤€ìˆ˜]
    {{
      "prediction": 1250000,
      "analysis": "ğŸ“ˆ ìƒìŠ¹ì„¸: ë§‘ì€ ë‚ ì”¨ë¡œ ìœ ë™ ì¸êµ¬ê°€ ëŠ˜ì–´ ì „ì£¼ ëŒ€ë¹„ 15% ìƒìŠ¹ íë¦„ì…ë‹ˆë‹¤.",
      "strategies": [
        {{ "category": "ì¸ë ¥", "icon": "ğŸ‘¥", "title": "í”¼í¬íƒ€ì„ ì§‘ì¤‘", "summary": "12ì‹œ~2ì‹œ ì•Œë°” ì¶”ê°€", "detail": "ì ì‹¬ í”¼í¬ê°€ ì˜ˆìƒë˜ë‹ˆ...", "score": 90 }},
        ...
      ],
      "cheer_msg": "ì‚¬ì¥ë‹˜, ì˜¤ëŠ˜ ëŒ€ë°• ì¡°ì§ì´ ë³´ì—¬ìš”! í˜ë‚´ì„¸ìš”! ğŸŒŸ"
    }}
    
    âš ï¸ ì˜¤ì§ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”. ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡(```json)ì„ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.
    """
    
    response_text = get_gemini_response(prompt)
    
    if response_text is None:
        return get_mock_dashboard_data(revenue_today)

    # JSON Parsing Logic
    try:
        # Clean potential markdown
        clean_text = re.sub(r'```json\s*|\s*```', '', response_text).strip()
        data = json.loads(clean_text)
        return data
    except Exception as e:
        logger.error(f"Failed to parse Unified AI JSON: {e}. Raw: {response_text}")
        return get_mock_dashboard_data(revenue_today)

# Legacy functions kept for individual testing if needed, or can be removed.
def analyze_sales_flow(sales_data, weather_data): pass
def suggest_operational_strategy(sales_data, inventory_data, weather_data): pass
def get_emotional_care_message(): pass
def predict_revenue_with_ai(history_data, weather_data, inventory_data, event_data): pass
def consult_ai(question):
    prompt = f"ì§ˆë¬¸: {question}. ë‹µë³€:"
    return get_gemini_response(prompt)
